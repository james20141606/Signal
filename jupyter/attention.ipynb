{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "try to give different features different importance\n",
    "\n",
    "problems to solve:\n",
    "- implement attention and self attention\n",
    "- combined with MDN/ or without MDN, only MLP combined with attention!\n",
    "- fix the input features dimension?\n",
    "- some feature may contain NaN, assign it a value but fix the attention under a threshold\n",
    "- [maxout](https://github.com/Duncanswilson/maxout-pytorch/blob/master/maxout_pytorch.ipynb)\n",
    "- [ptrnetwork](https://github.com/uhauha2929/examples/blob/master/PtrNet.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import gc, argparse, sys, os, errno\n",
    "%pylab inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "sns.set_style('whitegrid')\n",
    "import h5py\n",
    "import os\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import scipy\n",
    "import sklearn\n",
    "from scipy.stats import pearsonr\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.projection = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, 64),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, encoder_outputs):\n",
    "        # (B, L, H) -> (B , L, 1)\n",
    "        energy = self.projection(encoder_outputs)\n",
    "        weights = F.softmax(energy.squeeze(-1), dim=1)\n",
    "        # (B, L, H) * (B, L, 1) -> (B, H)\n",
    "        outputs = (encoder_outputs * weights.unsqueeze(-1)).sum(dim=1)\n",
    "        return outputs, weights\n",
    "\n",
    "class AttnClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, bidirectional=True)\n",
    "        self.attention = SelfAttention(hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def set_embedding(self, vectors):\n",
    "        self.embedding.weight.data.copy_(vectors)\n",
    "\n",
    "    def forward(self, inputs, lengths):\n",
    "        batch_size = inputs.size(1)\n",
    "        # (L, B)\n",
    "        embedded = self.embedding(inputs)\n",
    "        # (L, B, E)\n",
    "        packed_emb = nn.utils.rnn.pack_padded_sequence(embedded, lengths)\n",
    "        out, hidden = self.lstm(packed_emb)\n",
    "        out = nn.utils.rnn.pad_packed_sequence(out)[0]\n",
    "        out = out[:, :, :self.hidden_dim] + out[:, :, self.hidden_dim:]\n",
    "        # (L, B, H)\n",
    "        embedding, attn_weights = self.attention(out.transpose(0, 1))\n",
    "        # (B, HOP, H)\n",
    "        outputs = self.fc(embedding.view(batch_size, -1))\n",
    "        # (B, 1)\n",
    "        return outputs, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "from torchtext.vocab import GloVe\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "batch_size = 64\n",
    "embedding_dim = 200\n",
    "hidden_dim = 200\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading aclImdb_v1.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".vector_cache/glove.6B.zip: 862MB [04:22, 3.28MB/s]                               \n",
      "100%|██████████| 400000/400000 [00:22<00:00, 17552.61it/s]\n"
     ]
    }
   ],
   "source": [
    "# define Field\n",
    "TEXT = data.Field(lower=True, include_lengths=True)\n",
    "LABEL = data.Field(sequential=False)\n",
    "# make splits for data\n",
    "train, test = datasets.IMDB.splits(TEXT, LABEL)\n",
    "# build the vocabulary\n",
    "TEXT.build_vocab(train, vectors=GloVe(name='6B', dim=embedding_dim))\n",
    "LABEL.build_vocab(train)\n",
    "\n",
    "train_iter, test_iter = data.BucketIterator.splits(\n",
    "        (train, test), sort_key=lambda x:len(x.text),\n",
    "        sort_within_batch=True, \n",
    "        batch_size=batch_size, device=device,\n",
    "        repeat=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_iter, model, optimizer, criterion):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    bar = tqdm(total=len(train_iter))\n",
    "    b_ix = 1\n",
    "    for batch in train_iter:\n",
    "        (x, x_l), y = batch.text, batch.label - 1\n",
    "        optimizer.zero_grad()\n",
    "        outputs, _ = model(x, x_l)\n",
    "        loss = criterion(outputs.view(-1), y.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        if b_ix % 10 == 0:\n",
    "            bar.update(10)\n",
    "            bar.set_description('current loss:{:.4f}'.format(epoch_loss / b_ix))\n",
    "        b_ix += 1\n",
    "    bar.update((b_ix - 1) % 10)\n",
    "    bar.close()\n",
    "    return epoch_loss / len(train_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "current loss:0.3877: 100%|██████████| 391/391 [00:21<00:00, 18.49it/s]\n",
      "current loss:0.1423: 100%|██████████| 391/391 [00:20<00:00, 18.66it/s]\n",
      "current loss:0.0147: 100%|██████████| 391/391 [00:21<00:00, 18.57it/s]\n",
      "current loss:0.0021: 100%|██████████| 391/391 [00:21<00:00, 18.53it/s]\n",
      "current loss:0.0004: 100%|██████████| 391/391 [00:21<00:00, 18.48it/s]\n"
     ]
    }
   ],
   "source": [
    "model = AttnClassifier(len(TEXT.vocab), embedding_dim, hidden_dim).to(device)\n",
    "model.set_embedding(TEXT.vocab.vectors)\n",
    "# optim\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.BCEWithLogitsLoss().to(device)\n",
    "# train model \n",
    "for epoch in range(epochs):\n",
    "    train(train_iter, model, optimizer, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_accuracy(preds, y):\n",
    "    # round predictions to the closest integer\n",
    "    rounded_preds = torch.round(F.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).float()  # convert into float for division\n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc\n",
    "\n",
    "def accuracy(model, test_iter):\n",
    "    model.eval()\n",
    "    total_acc = 0\n",
    "    for batch in test_iter:\n",
    "        (x, x_l), y = batch.text, batch.label - 1\n",
    "        outputs,_ = model(x, x_l)\n",
    "        total_acc += binary_accuracy(outputs.view(-1), y.float()).item()\n",
    "    return total_acc / len(test_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.867814897728698\n"
     ]
    }
   ],
   "source": [
    "print(accuracy(model, test_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight(word, attn):\n",
    "    html_color = '#%02X%02X%02X' % (255, int(255*(1 - attn)), int(255*(1 - attn)))\n",
    "    return '<span style=\"background-color: {}\">{}</span>'.format(html_color, word)\n",
    "\n",
    "def mk_html(seq, attns):\n",
    "    html = \"\"\n",
    "    for ix, attn in zip(seq, attns):\n",
    "        html += ' ' + highlight(\n",
    "            TEXT.vocab.itos[ix],\n",
    "            attn\n",
    "        )\n",
    "    return html + \"<br><br>\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       " <span style=\"background-color: #FFFCFC\">a</span> <span style=\"background-color: #FFF4F4\">really</span> <span style=\"background-color: #FFF3F3\">realistic,</span> <span style=\"background-color: #FFE6E6\">sensible</span> <span style=\"background-color: #FFF0F0\">movie</span> <span style=\"background-color: #FFF9F9\">by</span> <span style=\"background-color: #FFE3E3\">ramgopal</span> <span style=\"background-color: #FFF8F8\">verma</span> <span style=\"background-color: #FFFDFD\">.</span> <span style=\"background-color: #FFFEFE\">no</span> <span style=\"background-color: #FFF4F4\">stupidity</span> <span style=\"background-color: #FFFEFE\">like</span> <span style=\"background-color: #FFFEFE\">songs</span> <span style=\"background-color: #FFFEFE\">as</span> <span style=\"background-color: #FFFEFE\">in</span> <span style=\"background-color: #FFFEFE\">other</span> <span style=\"background-color: #FFFDFD\">hindi</span> <span style=\"background-color: #FFFCFC\">movies.</span> <span style=\"background-color: #FFFDFD\">class</span> <span style=\"background-color: #FFFCFC\">acting</span> <span style=\"background-color: #FFFCFC\">by</span> <span style=\"background-color: #FFECEC\">nana</span> <span style=\"background-color: #FFEEEE\">patekar.</span> <span style=\"background-color: #FFE6E6\"><br</span> <span style=\"background-color: #FFD9D9\">/><br</span> <span style=\"background-color: #FFEEEE\">/>much</span> <span style=\"background-color: #FFF5F5\">similarities</span> <span style=\"background-color: #FFFEFE\">to</span> <span style=\"background-color: #FFFDFD\">real</span> <span style=\"background-color: #FFFBFB\"><unk></span><br><br>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " <span style=\"background-color: #FFD6D6\">this</span> <span style=\"background-color: #FFD6D6\">movie</span> <span style=\"background-color: #FFF0F0\">turned</span> <span style=\"background-color: #FFFBFB\">out</span> <span style=\"background-color: #FFFCFC\">to</span> <span style=\"background-color: #FFFDFD\">be</span> <span style=\"background-color: #FFFCFC\">better</span> <span style=\"background-color: #FFFDFD\">than</span> <span style=\"background-color: #FFFCFC\">i</span> <span style=\"background-color: #FFFDFD\">had</span> <span style=\"background-color: #FFFDFD\">expected</span> <span style=\"background-color: #FFFDFD\">it</span> <span style=\"background-color: #FFFDFD\">to</span> <span style=\"background-color: #FFFAFA\">be.</span> <span style=\"background-color: #FFFDFD\">some</span> <span style=\"background-color: #FFFDFD\">parts</span> <span style=\"background-color: #FFFDFD\">were</span> <span style=\"background-color: #FFFBFB\">pretty</span> <span style=\"background-color: #FFF3F3\">funny.</span> <span style=\"background-color: #FFFAFA\">it</span> <span style=\"background-color: #FFF7F7\">was</span> <span style=\"background-color: #FFCCCC\">nice</span> <span style=\"background-color: #FFF9F9\">to</span> <span style=\"background-color: #FFFCFC\">have</span> <span style=\"background-color: #FFFCFC\">a</span> <span style=\"background-color: #FFF6F6\">movie</span> <span style=\"background-color: #FFFAFA\">with</span> <span style=\"background-color: #FFFCFC\">a</span> <span style=\"background-color: #FFFAFA\">new</span> <span style=\"background-color: #FFE8E8\">plot.</span><br><br>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " <span style=\"background-color: #FFFCFC\">you</span> <span style=\"background-color: #FFFDFD\">may</span> <span style=\"background-color: #FFFDFD\">like</span> <span style=\"background-color: #FFFDFD\">tim</span> <span style=\"background-color: #FFFBFB\">burton's</span> <span style=\"background-color: #FFFCFC\">fantasies,</span> <span style=\"background-color: #FFFDFD\">but</span> <span style=\"background-color: #FFFEFE\">not</span> <span style=\"background-color: #FFFEFE\">in</span> <span style=\"background-color: #FFFEFE\">a</span> <span style=\"background-color: #FFFAFA\"><unk></span> <span style=\"background-color: #FFFDFD\">show</span> <span style=\"background-color: #FFFDFD\">off</span> <span style=\"background-color: #FFDCDC\">lasting</span> <span style=\"background-color: #FFF0F0\">8</span> <span style=\"background-color: #FFE0E0\">minutes.</span> <span style=\"background-color: #FFF7F7\">it</span> <span style=\"background-color: #FFE3E3\">demonstrates</span> <span style=\"background-color: #FFD9D9\">good</span> <span style=\"background-color: #FFEAEA\">technical</span> <span style=\"background-color: #FFF3F3\">points</span> <span style=\"background-color: #FFFCFC\">without</span> <span style=\"background-color: #FFFCFC\">real</span> <span style=\"background-color: #FFFCFC\">creativity</span> <span style=\"background-color: #FFFDFD\">or</span> <span style=\"background-color: #FFFEFE\">some</span> <span style=\"background-color: #FFFCFC\">established</span> <span style=\"background-color: #FFF7F7\">narrative</span> <span style=\"background-color: #FFEFEF\">pace.</span> <span style=\"background-color: #FFF4F4\"><pad></span><br><br>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " <span style=\"background-color: #FFFBFB\">it's</span> <span style=\"background-color: #FFFEFE\">not</span> <span style=\"background-color: #FFFEFE\">citizen</span> <span style=\"background-color: #FFF8F8\">kane,</span> <span style=\"background-color: #FFFEFE\">but</span> <span style=\"background-color: #FFFEFE\">it</span> <span style=\"background-color: #FFFDFD\">does</span> <span style=\"background-color: #FFE1E1\">deliver.</span> <span style=\"background-color: #FFECEC\">cleavage,</span> <span style=\"background-color: #FFFDFD\">and</span> <span style=\"background-color: #FFFCFC\">lots</span> <span style=\"background-color: #FFFDFD\">of</span> <span style=\"background-color: #FFF6F6\">it.<br</span> <span style=\"background-color: #FFDEDE\">/><br</span> <span style=\"background-color: #FFDEDE\">/>badly</span> <span style=\"background-color: #FFF0F0\">acted</span> <span style=\"background-color: #FFFAFA\">and</span> <span style=\"background-color: #FFE8E8\">directed,</span> <span style=\"background-color: #FFC5C5\">poorly</span> <span style=\"background-color: #FFFAFA\">scripted.</span> <span style=\"background-color: #FFFDFD\">who</span> <span style=\"background-color: #FFFDFD\">cares?</span> <span style=\"background-color: #FFFDFD\">i</span> <span style=\"background-color: #FFFCFC\">didn't</span> <span style=\"background-color: #FFFEFE\">watch</span> <span style=\"background-color: #FFFEFE\">it</span> <span style=\"background-color: #FFFEFE\">for</span> <span style=\"background-color: #FFFEFE\">the</span> <span style=\"background-color: #FFFDFD\">dialog.</span> <span style=\"background-color: #FFFEFE\"><pad></span><br><br>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " <span style=\"background-color: #FFFAFA\">subject</span> <span style=\"background-color: #FFEEEE\">matter:</span> <span style=\"background-color: #FFEFEF\"><unk></span> <span style=\"background-color: #FFF9F9\">quantum</span> <span style=\"background-color: #FFFEFE\">physics</span> <span style=\"background-color: #FFFEFE\">and</span> <span style=\"background-color: #FFFDFD\">stephen</span> <span style=\"background-color: #FFEFEF\"><unk></span> <span style=\"background-color: #FFDFDF\">/><br</span> <span style=\"background-color: #FFE4E4\"><unk></span> <span style=\"background-color: #FFF4F4\">phillip</span> <span style=\"background-color: #FFEAEA\"><unk></span> <span style=\"background-color: #FFE5E5\">/><br</span> <span style=\"background-color: #FFEAEA\">/>have</span> <span style=\"background-color: #FFFBFB\">i</span> <span style=\"background-color: #FFFEFE\">died</span> <span style=\"background-color: #FFFEFE\">and</span> <span style=\"background-color: #FFFEFE\">gone</span> <span style=\"background-color: #FFFEFE\">to</span> <span style=\"background-color: #FFFAFA\">heaven?</span> <span style=\"background-color: #FFF7F7\"><br</span> <span style=\"background-color: #FFF1F1\">/><br</span> <span style=\"background-color: #FFF5F5\">/>you</span> <span style=\"background-color: #FFFDFD\">will</span> <span style=\"background-color: #FFFDFD\">be</span> <span style=\"background-color: #FFF3F3\">enraptured.</span> <span style=\"background-color: #FFFDFD\"><pad></span> <span style=\"background-color: #FFFDFD\"><pad></span> <span style=\"background-color: #FFFDFD\"><pad></span> <span style=\"background-color: #FFFDFD\"><pad></span><br><br>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " <span style=\"background-color: #FFEBEB\">you've</span> <span style=\"background-color: #FFF6F6\">got</span> <span style=\"background-color: #FFFDFD\">to</span> <span style=\"background-color: #FFFDFD\">be</span> <span style=\"background-color: #FFF1F1\">kidding.</span> <span style=\"background-color: #FFE7E7\">this</span> <span style=\"background-color: #FFE1E1\">movie</span> <span style=\"background-color: #FFEAEA\">sucked</span> <span style=\"background-color: #FFFBFB\">for</span> <span style=\"background-color: #FFF8F8\">the</span> <span style=\"background-color: #FFEDED\">sci-fi</span> <span style=\"background-color: #FFF2F2\">fans.</span> <span style=\"background-color: #FFF8F8\">i</span> <span style=\"background-color: #FFFCFC\">would</span> <span style=\"background-color: #FFFDFD\">only</span> <span style=\"background-color: #FFF1F1\">recommend</span> <span style=\"background-color: #FFF9F9\">watching</span> <span style=\"background-color: #FFFAFA\">this</span> <span style=\"background-color: #FFFBFB\">only</span> <span style=\"background-color: #FFFDFD\">if</span> <span style=\"background-color: #FFFCFC\">you</span> <span style=\"background-color: #FFFCFC\">think</span> <span style=\"background-color: #FFFAFA\">armageddon</span> <span style=\"background-color: #FFFBFB\">was</span> <span style=\"background-color: #FFF1F1\">good.</span> <span style=\"background-color: #FFF8F8\"><pad></span> <span style=\"background-color: #FFF8F8\"><pad></span> <span style=\"background-color: #FFF8F8\"><pad></span> <span style=\"background-color: #FFF8F8\"><pad></span> <span style=\"background-color: #FFF8F8\"><pad></span><br><br>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " <span style=\"background-color: #FFFEFE\">widow</span> <span style=\"background-color: #FFFDFD\">hires</span> <span style=\"background-color: #FFFDFD\">a</span> <span style=\"background-color: #FFF9F9\">psychopath</span> <span style=\"background-color: #FFFDFD\">as</span> <span style=\"background-color: #FFFCFC\">a</span> <span style=\"background-color: #FFF5F5\"><unk></span> <span style=\"background-color: #FFA5A5\">sloppy</span> <span style=\"background-color: #FFECEC\">film</span> <span style=\"background-color: #FFD4D4\">noir</span> <span style=\"background-color: #FFE4E4\">thriller</span> <span style=\"background-color: #FFFAFA\">which</span> <span style=\"background-color: #FFFAFA\">doesn't</span> <span style=\"background-color: #FFFDFD\">make</span> <span style=\"background-color: #FFFEFE\">much</span> <span style=\"background-color: #FFFEFE\">of</span> <span style=\"background-color: #FFFEFE\">its</span> <span style=\"background-color: #FFFCFC\">tension</span> <span style=\"background-color: #FFFAFA\">promising</span> <span style=\"background-color: #FFF7F7\">set-up.</span> <span style=\"background-color: #FFF7F7\">(3/10)</span> <span style=\"background-color: #FFFCFC\"><pad></span> <span style=\"background-color: #FFFCFC\"><pad></span> <span style=\"background-color: #FFFCFC\"><pad></span> <span style=\"background-color: #FFFCFC\"><pad></span> <span style=\"background-color: #FFFCFC\"><pad></span> <span style=\"background-color: #FFFCFC\"><pad></span> <span style=\"background-color: #FFFCFC\"><pad></span> <span style=\"background-color: #FFFCFC\"><pad></span> <span style=\"background-color: #FFFCFC\"><pad></span><br><br>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " <span style=\"background-color: #FFFCFC\">if</span> <span style=\"background-color: #FFFDFD\">you</span> <span style=\"background-color: #FFFDFD\">like</span> <span style=\"background-color: #FFC7C7\">pauly</span> <span style=\"background-color: #FFE3E3\">shore,</span> <span style=\"background-color: #FFF7F7\">you'll</span> <span style=\"background-color: #FFFDFD\">love</span> <span style=\"background-color: #FFFEFE\">son</span> <span style=\"background-color: #FFFEFE\">in</span> <span style=\"background-color: #FFFCFC\">law.</span> <span style=\"background-color: #FFFEFE\">if</span> <span style=\"background-color: #FFFEFE\">you</span> <span style=\"background-color: #FFFDFD\">hate</span> <span style=\"background-color: #FFEDED\">pauly</span> <span style=\"background-color: #FFF2F2\">shore,</span> <span style=\"background-color: #FFEFEF\">then,</span> <span style=\"background-color: #FFEFEF\">well...i</span> <span style=\"background-color: #FFE7E7\">liked</span> <span style=\"background-color: #FFE7E7\">it!</span> <span style=\"background-color: #FFFBFB\"><pad></span> <span style=\"background-color: #FFFBFB\"><pad></span> <span style=\"background-color: #FFFBFB\"><pad></span> <span style=\"background-color: #FFFBFB\"><pad></span> <span style=\"background-color: #FFFBFB\"><pad></span> <span style=\"background-color: #FFFBFB\"><pad></span> <span style=\"background-color: #FFFBFB\"><pad></span> <span style=\"background-color: #FFFBFB\"><pad></span> <span style=\"background-color: #FFFBFB\"><pad></span> <span style=\"background-color: #FFFBFB\"><pad></span> <span style=\"background-color: #FFFBFB\"><pad></span><br><br>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " <span style=\"background-color: #FFEFEF\">this</span> <span style=\"background-color: #FFF4F4\">is</span> <span style=\"background-color: #FFF3F3\">a</span> <span style=\"background-color: #FFE7E7\">great</span> <span style=\"background-color: #FFC9C9\">movie.</span> <span style=\"background-color: #FFE8E8\">too</span> <span style=\"background-color: #FFE9E9\">bad</span> <span style=\"background-color: #FFFCFC\">it</span> <span style=\"background-color: #FFFDFD\">is</span> <span style=\"background-color: #FFFEFE\">not</span> <span style=\"background-color: #FFFEFE\">available</span> <span style=\"background-color: #FFFEFE\">on</span> <span style=\"background-color: #FFFEFE\">home</span> <span style=\"background-color: #FFFAFA\">video.</span> <span style=\"background-color: #FFF9F9\"><pad></span> <span style=\"background-color: #FFF9F9\"><pad></span> <span style=\"background-color: #FFF9F9\"><pad></span> <span style=\"background-color: #FFF9F9\"><pad></span> <span style=\"background-color: #FFF9F9\"><pad></span> <span style=\"background-color: #FFF9F9\"><pad></span> <span style=\"background-color: #FFF9F9\"><pad></span> <span style=\"background-color: #FFF9F9\"><pad></span> <span style=\"background-color: #FFF9F9\"><pad></span> <span style=\"background-color: #FFF9F9\"><pad></span> <span style=\"background-color: #FFF9F9\"><pad></span> <span style=\"background-color: #FFF9F9\"><pad></span> <span style=\"background-color: #FFF9F9\"><pad></span> <span style=\"background-color: #FFF9F9\"><pad></span> <span style=\"background-color: #FFF9F9\"><pad></span> <span style=\"background-color: #FFF9F9\"><pad></span><br><br>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " <span style=\"background-color: #FFFBFB\">more</span> <span style=\"background-color: #FFECEC\">suspenseful,</span> <span style=\"background-color: #FFFCFC\">more</span> <span style=\"background-color: #FFF2F2\">subtle,</span> <span style=\"background-color: #FFF7F7\">much,</span> <span style=\"background-color: #FFFCFC\">much</span> <span style=\"background-color: #FFFDFD\">more</span> <span style=\"background-color: #FFF7F7\"><unk></span> <span style=\"background-color: #FFF5F5\"><pad></span> <span style=\"background-color: #FFF5F5\"><pad></span> <span style=\"background-color: #FFF5F5\"><pad></span> <span style=\"background-color: #FFF5F5\"><pad></span> <span style=\"background-color: #FFF5F5\"><pad></span> <span style=\"background-color: #FFF5F5\"><pad></span> <span style=\"background-color: #FFF5F5\"><pad></span> <span style=\"background-color: #FFF5F5\"><pad></span> <span style=\"background-color: #FFF5F5\"><pad></span> <span style=\"background-color: #FFF5F5\"><pad></span> <span style=\"background-color: #FFF5F5\"><pad></span> <span style=\"background-color: #FFF5F5\"><pad></span> <span style=\"background-color: #FFF5F5\"><pad></span> <span style=\"background-color: #FFF5F5\"><pad></span> <span style=\"background-color: #FFF5F5\"><pad></span> <span style=\"background-color: #FFF5F5\"><pad></span> <span style=\"background-color: #FFF5F5\"><pad></span> <span style=\"background-color: #FFF5F5\"><pad></span> <span style=\"background-color: #FFF5F5\"><pad></span> <span style=\"background-color: #FFF5F5\"><pad></span> <span style=\"background-color: #FFF5F5\"><pad></span> <span style=\"background-color: #FFF5F5\"><pad></span><br><br>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " <span style=\"background-color: #FFF6F6\">primary</span> <span style=\"background-color: #FFE9E9\"><unk></span> <span style=\"background-color: #FFEDED\"><unk></span> <span style=\"background-color: #FFF1F1\">interpretation.</span> <span style=\"background-color: #FFF7F7\"><pad></span> <span style=\"background-color: #FFF7F7\"><pad></span> <span style=\"background-color: #FFF7F7\"><pad></span> <span style=\"background-color: #FFF7F7\"><pad></span> <span style=\"background-color: #FFF7F7\"><pad></span> <span style=\"background-color: #FFF7F7\"><pad></span> <span style=\"background-color: #FFF7F7\"><pad></span> <span style=\"background-color: #FFF7F7\"><pad></span> <span style=\"background-color: #FFF7F7\"><pad></span> <span style=\"background-color: #FFF7F7\"><pad></span> <span style=\"background-color: #FFF7F7\"><pad></span> <span style=\"background-color: #FFF7F7\"><pad></span> <span style=\"background-color: #FFF7F7\"><pad></span> <span style=\"background-color: #FFF7F7\"><pad></span> <span style=\"background-color: #FFF7F7\"><pad></span> <span style=\"background-color: #FFF7F7\"><pad></span> <span style=\"background-color: #FFF7F7\"><pad></span> <span style=\"background-color: #FFF7F7\"><pad></span> <span style=\"background-color: #FFF7F7\"><pad></span> <span style=\"background-color: #FFF7F7\"><pad></span> <span style=\"background-color: #FFF7F7\"><pad></span> <span style=\"background-color: #FFF7F7\"><pad></span> <span style=\"background-color: #FFF7F7\"><pad></span> <span style=\"background-color: #FFF7F7\"><pad></span> <span style=\"background-color: #FFF7F7\"><pad></span> <span style=\"background-color: #FFF7F7\"><pad></span><br><br>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import HTML, display\n",
    "with torch.no_grad():\n",
    "    for batch in test_iter:\n",
    "        x, x_l = batch.text\n",
    "        y = batch.label - 1\n",
    "        outputs, attn_weights = model(x, x_l)\n",
    "        for i in range(batch_size):\n",
    "            if torch.round(F.sigmoid(outputs[i])) != y[i].float():\n",
    "                text = mk_html(x.t()[i].cpu().numpy(), attn_weights[i].cpu().numpy())\n",
    "                display(HTML(text))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ptr network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'attention'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-e9720d1f7cd7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mattention\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mattend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'attention'"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "from torch import FloatTensor\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import Linear, Module\n",
    "\n",
    "from attention import attend\n",
    "\n",
    "\n",
    "seed = sum(map(ord, 'les bons mots'))\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "\n",
    "def Volatile(x):\n",
    "    return Variable(x, volatile=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data(object):\n",
    "    dim = 10\n",
    "    min_position, max_position = 3, 7\n",
    "    q_min = np.random.normal(0, 1, dim).astype(np.float32)\n",
    "    q_max = np.random.normal(0, 1, dim).astype(np.float32)\n",
    "    query = np.row_stack([q_min, q_max])\n",
    "\n",
    "    @staticmethod\n",
    "    def create_minibatches(n, m, min_length, max_length):\n",
    "        assert 0 < min_length <= max_length\n",
    "\n",
    "        minibatches = []\n",
    "        for i in range(n):\n",
    "            lengths = np.random.randint(min_length, max_length + 1, m)\n",
    "            context = np.zeros((m, lengths.max(), Data.dim), dtype=np.float32)\n",
    "            target = np.zeros((m, 2, Data.dim))\n",
    "            target_indices = []\n",
    "\n",
    "            for j, length in enumerate(lengths):\n",
    "                c = np.random.normal(0, 1, (length, Data.dim))\n",
    "                k_min = np.argmin(c[:,Data.min_position])\n",
    "                k_max = np.argmax(c[:,Data.max_position])\n",
    "                target_min = c[k_min]\n",
    "                target_max = c[k_max]\n",
    "                context[j,:length] = c\n",
    "                target[j,0] = target_min\n",
    "                target[j,1] = target_max\n",
    "                target_indices.append((k_min, k_max))\n",
    "\n",
    "            query = FloatTensor(np.tile(Data.query, (m, 1, 1)))\n",
    "            context = FloatTensor(context)\n",
    "            target = FloatTensor(target)\n",
    "            minibatches.append((query, context, target, lengths, target_indices))\n",
    "        return minibatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointerNet(Module):\n",
    "    def __init__(self, n_hidden):\n",
    "        super(PointerNet, self).__init__()\n",
    "        self.n_hidden = n_hidden\n",
    "        self.f = Linear(Data.dim, n_hidden)\n",
    "        self.g = Linear(Data.dim, n_hidden)\n",
    "\n",
    "    def forward(self, q, x, lengths=None, **kwargs):\n",
    "        batch_size_q, n_queries, dim_q = q.size()\n",
    "        batch_size_x, n_inputs, dim_x = x.size()\n",
    "        assert batch_size_q == batch_size_x\n",
    "        assert dim_q == dim_x\n",
    "        batch_size = batch_size_q\n",
    "        dim = dim_q\n",
    "\n",
    "        q_flat = q.view(batch_size*n_queries, dim)\n",
    "        u_flat = self.f(q_flat)\n",
    "        u = u_flat.view(batch_size, n_queries, self.n_hidden)\n",
    "\n",
    "        x_flat = x.view(batch_size*n_inputs, dim)\n",
    "        v_flat = self.g(x_flat)\n",
    "        v = v_flat.view(batch_size, n_inputs, self.n_hidden)\n",
    "\n",
    "        return attend(u, v, value=x, context_sizes=lengths, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "\n",
    "n_train = 200\n",
    "min_length_train, max_length_train = 5, 14\n",
    "train_batches = Data.create_minibatches(n_train, batch_size, min_length_train, max_length_train)\n",
    "\n",
    "n_valid = 100\n",
    "min_length_valid, max_length_valid = 15, 24\n",
    "valid_batches = Data.create_minibatches(n_valid, batch_size, min_length_valid, max_length_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = PointerNet(7)\n",
    "opt = torch.optim.RMSprop(net.parameters(), lr=0.001)\n",
    "mse = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 0\n",
    "max_epochs = 10\n",
    "while epoch < max_epochs:\n",
    "    sum_loss = 0\n",
    "    for query, context, target, lengths, target_indices in train_batches:\n",
    "        net.zero_grad()\n",
    "        output = net(Variable(query), Variable(context), lengths=lengths)\n",
    "        loss = mse(output, Variable(target))\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        sum_loss += loss.data[0]\n",
    "    epoch += 1\n",
    "    print('[{:2d}] {:5.3f}'.format(epoch, sum_loss / n_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_loss = 0\n",
    "sum_error_min = 0\n",
    "sum_error_max = 0\n",
    "for query, context, target, lengths, target_indices in valid_batches:\n",
    "    weight, output = net(Volatile(query), Volatile(context), lengths=lengths, return_weight=True)\n",
    "\n",
    "    loss = mse(output, Volatile(target))\n",
    "    sum_loss += loss.data[0]\n",
    "\n",
    "    weight = weight.data.numpy()\n",
    "    for i, (i_min_true, i_max_true) in enumerate(target_indices):\n",
    "        w_min, w_max = weight[i]\n",
    "        i_min_pred = w_min.argmax()\n",
    "        i_max_pred = w_max.argmax()\n",
    "        sum_error_min += int(i_min_true != i_min_pred)\n",
    "        sum_error_max += int(i_max_true != i_max_pred)\n",
    "\n",
    "print('valid loss: {:5.3f}'.format(sum_loss / n_valid))\n",
    "print('valid error min: {:5.3f}'.format(sum_error_min / (n_valid * batch_size)))\n",
    "print('valid error max: {:5.3f}'.format(sum_error_max / (n_valid * batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query, context, target, lengths, target_indices = valid_batches[0]\n",
    "weight, output = net(Volatile(query), Volatile(context), lengths=lengths, return_weight=True)\n",
    "context = context.numpy()\n",
    "weight = weight.data.numpy()\n",
    "\n",
    "colors = sns.color_palette('husl', 3)\n",
    "fig, axs = plt.subplots(batch_size, 2, figsize=(10, 10), sharex=True, sharey=True)\n",
    "axs_min, axs_max = axs[:,0], axs[:,1]\n",
    "\n",
    "for i, (i_min, i_max) in enumerate(target_indices):\n",
    "    length = lengths[i]\n",
    "    w_min, w_max = weight[i]\n",
    "    c_min = [context[i,j,Data.min_position] for j in range(length)]\n",
    "    c_max = [context[i,j,Data.max_position] for j in range(length)]\n",
    "\n",
    "    axs_min[i].axvline(i_min, zorder=1, color=colors[2], label='min value')\n",
    "    axs_min[i].bar(np.arange(length) - 0.4, c_min, zorder=2, color=colors[1], lw=0, label='values')\n",
    "    axs_min[i].plot(np.arange(length), w_min[:length], zorder=3, color=colors[0], label='attention')\n",
    "\n",
    "    axs_max[i].axvline(i_max, zorder=1, color=colors[2], label='max value')\n",
    "    axs_max[i].bar(np.arange(length) - 0.4, c_max, zorder=2, color=colors[1], lw=0, label='values')\n",
    "    axs_max[i].plot(np.arange(length), w_max[:length], zorder=3, color=colors[0], label='attention')\n",
    "\n",
    "axs_min[0].set_title('Minimum')\n",
    "axs_max[0].set_title('Maximum')\n",
    "axs_max[0].legend(loc='best')    \n",
    "axs_min[0].legend(loc='best')\n",
    "axs_max[0].legend(loc='best')\n",
    "axs_min[-1].set_xlabel('position')\n",
    "axs_max[-1].set_xlabel('position')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP with attention\n",
    "use the idea from MOTIF problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten, Lambda\n",
    "from keras.layers.merge import Multiply\n",
    "from keras.models import Model\n",
    "from keras.layers.merge import Concatenate, Add\n",
    "from keras.layers.convolutional import Conv1D, Conv2D\n",
    "from keras.layers.pooling import MaxPooling1D, MaxPooling2D, GlobalMaxPooling1D, GlobalMaxPooling2D, AveragePooling1D\n",
    "from keras.layers.convolutional import UpSampling1D, UpSampling2D\n",
    "from keras.regularizers import l2, l1, l1_l2\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.wrappers import Bidirectional\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "def set_keras_num_threads(n_threads):\n",
    "    from keras import backend as K\n",
    "    import tensorflow as tf\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    config.intra_op_parallelism_threads = n_threads\n",
    "    config.inter_op_parallelism_threads = n_threads\n",
    "    K.set_session(tf.Session(config=config))\n",
    "    \n",
    "set_keras_num_threads(2)\n",
    "\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def sigmoid(x):\n",
    "    return 1.0/(1.0 + np.exp(-x))\n",
    "\n",
    "def soft_window_numpy(x, w=1, c=0, t=10.0):\n",
    "    y_curve = np.where(x <= c,\n",
    "                       sigmoid(t*(x - (c - 0.5*w))),\n",
    "                       sigmoid(t*(-x + (c + 0.5*w))))\n",
    "    return y_curve\n",
    "\n",
    "def soft_window2(x, w=0.5, c=0, k=0.25, t=10.0):\n",
    "    y_curve = np.where(x <= c,\n",
    "                       sigmoid(t*(x - (c - 0.5*w))),\n",
    "                       sigmoid(t*(-x + (c + 0.5*w))))\n",
    "    y_linear = np.where(x <= c, x + 1 - c, -x + 1 + c)\n",
    "    y_linear = np.where(x <= c, (x + 1)/(c + 1), (x - 1)/(c - 1))\n",
    "    return 0.8*y_curve + 0.2*y_linear\n",
    "\n",
    "x = np.linspace(-1, 1, 128, dtype=np.float32)\n",
    "window = soft_window_numpy(x, c=64/64 - 1, w=20*2/128, t=30.0)\n",
    "fig, ax = plt.subplots(figsize=(16, 3))\n",
    "ax.plot(np.arange(128), window)\n",
    "ax.set_ylim(0, 1.5)\n",
    "\n",
    "x = np.linspace(-1, 1, 128, dtype=np.float32)\n",
    "window2 = soft_window2(x, c=-0.99, w=20*2/128, k=0.1, t=30.0)\n",
    "fig, ax = plt.subplots(figsize=(16, 3))\n",
    "ax.plot(x, window2)\n",
    "ax.set_ylim(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_network(input_layer):\n",
    "    output = Conv1D(64, 8, padding='valid', kernel_regularizer=l2(0.0005))(input_layer)\n",
    "    output = Activation('relu')(output)\n",
    "    output = MaxPooling1D(2)(output)\n",
    "    output = Conv1D(64, 4, padding='valid', kernel_regularizer=l2(0.0005))(output)\n",
    "    output = Activation('relu')(output)\n",
    "    output = MaxPooling1D(2)(output)\n",
    "    output = Flatten()(output)\n",
    "    #output = Dense(64, kernel_regularizer=l2(0.0001))(output)\n",
    "    return output\n",
    "\n",
    "def soft_window(x, c, w, t):\n",
    "    c = K.reshape(c, (-1, 1))\n",
    "    w = K.reshape(w, (-1, 1))\n",
    "    return K.switch(x <= c, \n",
    "                    K.sigmoid(t*(x - (c - 0.5*w))),\n",
    "                    K.sigmoid(t*(-x + (c + 0.5*w))))\n",
    "    \n",
    "def direct_cnn(window_size=128, n_channels=4):\n",
    "    input_layer = Input(shape=(window_size, n_channels))\n",
    "    output = conv_network(input_layer)\n",
    "    output = Dense(1)(output)\n",
    "    output = Activation('sigmoid')(output)\n",
    "    model = Model(inputs=[input_layer], outputs=[output])\n",
    "    return model\n",
    "    \n",
    "def attention_cnn(window_size=128, n_channels=4, t=15.0):\n",
    "    def attention_function(params):\n",
    "        x = np.linspace(-1, 1, window_size).astype(np.float32).reshape((1, window_size))\n",
    "        c = K.reshape(params, (-1, 1))\n",
    "        c = K.tanh(c)\n",
    "        #c = K.reshape(params[:, 0], (-1, 1))\n",
    "        #w = K.reshape(params[:, 1], (-1, 1))\n",
    "        #w = K.exp(w)\n",
    "        w = 20*2.0/window_size\n",
    "        k = 0.001\n",
    "        y_linear = [(x + 1)/(c + 1), (x - 1)/(c - 1)]\n",
    "        y_linear = [(x + 1 - c), (-x + 1 + c)]\n",
    "        y_curve  =  [K.sigmoid(t*(x - (c - 0.5*w))), K.sigmoid(t*(-x + (c + 0.5*w)))]\n",
    "        y = K.switch(x <= c, \n",
    "                     (1 - k)*y_curve[0] + k*y_linear[0],\n",
    "                     (1 - k)*y_curve[1] + k*y_linear[1])\n",
    "        y = K.expand_dims(y, axis=-1)\n",
    "        return y\n",
    "    \n",
    "    input_layer = Input(shape=(window_size, n_channels))\n",
    "    conv_attention = conv_network(input_layer)\n",
    "    attention_params = Dense(64, name='attention_dense1', activation='relu')(conv_attention)\n",
    "    attention_params = Dense(64, name='attention_dense2', activation='relu')(attention_params)\n",
    "    attention_params = Dense(1, name='attention_params')(attention_params)\n",
    "    attention = Lambda(attention_function, name='attention')(attention_params)\n",
    "    weighted_input = Multiply(name='multiply_attention')([input_layer, attention])\n",
    "    conv_predict = conv_network(weighted_input)\n",
    "    output = Dense(1, kernel_regularizer=l2(0.0005))(conv_predict)\n",
    "    output = Activation('sigmoid')(output)\n",
    "    \n",
    "    model = Model(inputs=[input_layer], outputs=[output])\n",
    "    return model, attention_params, attention\n",
    "\n",
    "def stochastic_attention_cnn(window_size=128, n_channels=4, t=10.0, \n",
    "                             n_sampler=10, sampler_stddev=1.0):\n",
    "    def attention_function(params):\n",
    "        x = np.linspace(-1, 1, window_size).astype(np.float32).reshape((1, window_size))\n",
    "        c = K.reshape(params, (-1, 1))\n",
    "        c = K.tanh(c)\n",
    "        #c = K.reshape(params[:, 0], (-1, 1))\n",
    "        #w = K.reshape(params[:, 1], (-1, 1))\n",
    "        #w = K.exp(w)\n",
    "        w = 20*2.0/window_size\n",
    "        y_curve  =  [K.sigmoid(t*(x - (c - 0.5*w))), K.sigmoid(t*(-x + (c + 0.5*w)))]\n",
    "        y = K.switch(x <= c, y_curve[0], y_curve[1])\n",
    "        y = K.expand_dims(y, axis=-1)\n",
    "        return y\n",
    "\n",
    "    def attention_sampler(attention_params):\n",
    "        n_samples = K.shape(attention_params)[0]\n",
    "        noise = K.random_normal((n_samples, n_sampler, 1), stddev=sampler_stddev*50/window_size)\n",
    "        attention_params = K.expand_dims(attention_params, axis=1)\n",
    "        attention_params = attention_params + noise\n",
    "        attention_params = K.reshape(attention_params, (-1, 1))\n",
    "        \n",
    "        c = attention_params\n",
    "        x = np.linspace(-1, 1, window_size).astype(np.float32).reshape((1, window_size))\n",
    "        c = K.tanh(c)\n",
    "        w = 20*2.0/window_size\n",
    "        y_curve  =  [K.sigmoid(t*(x - (c - 0.5*w))), K.sigmoid(t*(-x + (c + 0.5*w)))]\n",
    "        y = K.switch(x <= c, y_curve[0], y_curve[1])\n",
    "        y = K.expand_dims(y, axis=-1)\n",
    "        return y\n",
    "        \n",
    "        \n",
    "    input_layer = Input(shape=(window_size, n_channels))\n",
    "    conv_attention = conv_network(input_layer)\n",
    "    attention_params = Dense(64, name='attention_dense1', activation='relu')(conv_attention)\n",
    "    attention_params = Dense(64, name='attention_dense2', activation='relu')(attention_params)\n",
    "    attention_params = Dense(1, name='attention_params')(attention_params)\n",
    "    \n",
    "    attention = Lambda(lambda x: attention_sampler(x), name='attention_sampler')(attention_params)\n",
    "    repeated_input = Lambda(lambda x: K.repeat_elements(x, n_sampler, axis=0),\n",
    "                            name='repeated_input')(input_layer)\n",
    "    weighted_input = Multiply(name='multiply_attention')([repeated_input, attention])\n",
    "    conv_predict = conv_network(weighted_input)\n",
    "    output = Dense(1, kernel_regularizer=l2(0.0005), name='output_dense')(conv_predict)\n",
    "    output = Activation('sigmoid', name='output_sigmoid')(output)\n",
    "    output = Lambda(lambda x: K.mean(K.reshape(x, (-1, n_sampler, 1)), axis=1), name='output_mean')(output)\n",
    "    \n",
    "    model = Model(inputs=[input_layer], outputs=[output])\n",
    "    return model, attention_params, attention\n",
    "    \n",
    "#model, attention_params, attention = attention_cnn()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 128, 4)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 121, 64)      2112        input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 121, 64)      0           conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1D)  (None, 60, 64)       0           activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 57, 64)       16448       max_pooling1d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 57, 64)       0           conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1D)  (None, 28, 64)       0           activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 1792)         0           max_pooling1d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "attention_dense1 (Dense)        (None, 64)           114752      flatten_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "attention_dense2 (Dense)        (None, 64)           4160        attention_dense1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "attention_params (Dense)        (None, 1)            65          attention_dense2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "repeated_input (Lambda)         (None, 128, 4)       0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_sampler (Lambda)      (None, 128, 1)       0           attention_params[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "multiply_attention (Multiply)   (None, 128, 4)       0           repeated_input[0][0]             \n",
      "                                                                 attention_sampler[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 121, 64)      2112        multiply_attention[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 121, 64)      0           conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1D)  (None, 60, 64)       0           activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 57, 64)       16448       max_pooling1d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 57, 64)       0           conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling1D) (None, 28, 64)       0           activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 1792)         0           max_pooling1d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "output_dense (Dense)            (None, 1)            1793        flatten_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output_sigmoid (Activation)     (None, 1)            0           output_dense[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_mean (Lambda)            (None, 1)            0           output_sigmoid[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 157,890\n",
      "Trainable params: 157,890\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "attention_model, attention_params, attention = stochastic_attention_cnn()\n",
    "attention_model.summary()\n",
    "attention_model.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-37a68fbdd61b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mattention_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "attention_model.fit(X, y, batch_size=50, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 128, 4)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 121, 64)           2112      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 121, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 60, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 57, 64)            16448     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 57, 64)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 28, 64)            0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 1792)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 1793      \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 20,353\n",
      "Trainable params: 20,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = direct_cnn()\n",
    "model.summary()\n",
    "model.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X, y, batch_size=25, epochs=30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
